import asyncio
import time
import sys
from typing import Dict, Any, List, Optional
from bs4 import BeautifulSoup
import platform # ğŸš¨ platform ëª¨ë“ˆ ì¶”ê°€

if platform.system() == "Windows": # ğŸš¨ Windowsì—ì„œë§Œ ì‹¤í–‰í•˜ë„ë¡ ì¡°ê±´ ì¶”ê°€
    try:
        asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())
    except AttributeError:
        pass

DEFAULT_HEADERS = {
    "User-Agent": "Mozilla/5.0 (compatible; MyRunnerViewer/1.0; +https://example.com)"
}
class MyResultScraper:
    """
    MyResultScraper í´ë˜ìŠ¤ëŠ” Playwrightë¥¼ ì‚¬ìš©í•˜ì—¬
    ë™ì ìœ¼ë¡œ ë¡œë“œëœ ì›¹ í˜ì´ì§€ì—ì„œ ë‹¬ë¦¬ê¸° ê²½ì£¼ ê²°ê³¼ë¥¼ ìŠ¤í¬ë©í•©ë‹ˆë‹¤.
    """

    def __init__(self, base: str = "https://www.myresult.co.kr", delay_sec: float = 0.6, timeout: int = 15):
        self.base = base.rstrip("/")
        self.delay_sec = delay_sec
        self.timeout = timeout

    # -----------------------------
    # ê¸°ì¡´ ë‹¨ì¼ fetch í•¨ìˆ˜ (ìˆ˜ì • ì—†ìŒ)
    # -----------------------------
    def fetch_html(self, race_id: int, runner_id: int) -> Optional[str]:
        from playwright.sync_api import sync_playwright
        url = f"{self.base}/{race_id}/{runner_id}"
        print(f"[{race_id}/{runner_id}] ì ‘ì† ì‹œë„: {url}", file=sys.stderr)

        try:
            with sync_playwright() as p:
                browser = p.chromium.launch(headless=True, args=['--no-sandbox', '--disable-setuid-sandbox'])
                page = browser.new_page()
                page.goto(url, timeout=self.timeout * 1000)
                page.wait_for_selector("div.table-row.ant-row", timeout=8000)
                html = page.content()
                browser.close()
                print(f"[{race_id}/{runner_id}] HTML OK", file=sys.stderr)
                return html
        except Exception as e:
            print(f"[{race_id}/{runner_id}] [ì˜¤ë¥˜] HTML ì‹¤íŒ¨: {e}", file=sys.stderr)
            return None

    # -----------------------------
    # ê¸°ì¡´ íŒŒì„œ (ìˆ˜ì • ì—†ìŒ)
    # -----------------------------
    def parse_runner(self, html: str) -> Dict[str, Any]:
        soup = BeautifulSoup(html, "lxml")
        rows = soup.select("div.table-row.ant-row")
        sections = []

        for row in rows:
            cols = [div.get_text(strip=True) for div in row.select("div.ant-col.ant-col-6")]
            if not cols:
                continue
            sec = {
                "section": cols[0] if len(cols) > 0 else "",
                "pass_time": cols[1] if len(cols) > 1 else "",
                "split_time": cols[2] if len(cols) > 2 else "",
                "total_time": cols[3] if len(cols) > 3 else "",
            }
            sections.append(sec)

        name, gender, bib_no, event_name = "", "", "", ""

        try:
            name_tag = soup.select_one("div.ant-card-meta-detail > div.ant-card-meta-title")
            if name_tag:
                name = name_tag.get_text(strip=True)
            desc_tag = soup.select_one("div.ant-card-meta-detail > div.ant-card-meta-description")
            if desc_tag:
                parts = [p.strip() for p in desc_tag.get_text(strip=True).split("|")]
                if len(parts) >= 1:
                    gender = parts[0].strip()
                if len(parts) >= 2:
                    bib_no = parts[1].replace("#", "").strip()
            event_tag = soup.find("div", class_="ant-card-head-title")
            if event_tag:
                event_name = event_tag.get_text(strip=True)
        except Exception as e:
            print(f"ë©”íƒ€ë°ì´í„° ì¶”ì¶œ ì˜¤ë¥˜: {e}", file=sys.stderr)

        return {
            "name": name or "ì´ë¦„ì—†ìŒ",
            "gender": gender,
            "bib_no": bib_no,
            "event_name": event_name,
            "sections": sections,
        }

    def get_runner(self, race_id: int, runner_id: int) -> Dict[str, Any]:
        """ë‹¨ì¼ ì£¼ì ë°ì´í„°"""
        time.sleep(self.delay_sec)
        html = self.fetch_html(race_id, runner_id)
        if not html:
            return {"runner_id": runner_id, "error": "fetch_failed"}
        parsed = self.parse_runner(html)
        parsed["runner_id"] = runner_id
        return parsed

    # -----------------------------
    # âœ… ë³‘ë ¬ ë²„ì „ ì¶”ê°€
    # -----------------------------
    async def fetch_html_async(self, race_id: int, runner_id: int):
        """Playwright async ë²„ì „"""
        from playwright.async_api import async_playwright
        url = f"{self.base}/{race_id}/{runner_id}"
        print(f"[async] {race_id}/{runner_id} ì ‘ì† ì¤‘...", file=sys.stderr)
        try:
            async with async_playwright() as p:
                browser = await p.chromium.launch(headless=True, args=['--no-sandbox', '--disable-setuid-sandbox'])
                page = await browser.new_page()
                await page.goto(url, timeout=self.timeout * 1000)
                await page.wait_for_selector("div.table-row.ant-row", timeout=8000)
                html = await page.content()
                await browser.close()
                return runner_id, html
        except Exception as e:
            print(f"[async] {race_id}/{runner_id} ì‹¤íŒ¨: {e}", file=sys.stderr)
            return runner_id, None

    async def _get_many_async(self, race_id: int, runner_ids: list[int], limit: int = 4):
        """ë‚´ë¶€ async ì‹¤í–‰ê¸° â€” ë™ì‹œì— limitê°œì”© ì‹¤í–‰"""
        sem = asyncio.Semaphore(limit)
        results = []

        async def sem_task(runner_id):
            async with sem:
                _, html = await self.fetch_html_async(race_id, runner_id)
                if html:
                    parsed = self.parse_runner(html)
                    parsed["runner_id"] = runner_id
                    results.append(parsed)
                else:
                    results.append({"runner_id": runner_id, "error": "fetch_failed"})

        await asyncio.gather(*(sem_task(rid) for rid in runner_ids))
        return results

    def get_many(self, race_id: int, runner_ids: list[int], limit: int = 5):
        """ë¹„ë™ê¸° ë³‘ë ¬ ì‹¤í–‰ (ì™¸ë¶€ì—ì„œ í˜¸ì¶œìš©)"""
        return asyncio.run(self._get_many_async(race_id, runner_ids, limit))
