import sys
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Dict, Any, List
from bs4 import BeautifulSoup
from playwright.sync_api import sync_playwright, TimeoutError as PlaywrightTimeoutError

class MyResultScraper:
    """Playwright(sync) ê¸°ë°˜ â€” Windows/Linux ì™„ì „ í˜¸í™˜ ë²„ì „"""

    def __init__(self, base="https://www.myresult.co.kr", timeout=15):
        self.base = base.rstrip("/")
        self.timeout = timeout

    def fetch_html_sync(self, race_id: int, runner_id: int):
        """Playwrightë¥¼ ì‚¬ìš©í•´ HTMLì„ ê°€ì ¸ì˜¤ëŠ” ë™ê¸° ë²„ì „"""
        url = f"{self.base}/{race_id}/{runner_id}"
        print(f"[sync] {race_id}/{runner_id} ì ‘ì† ì¤‘...", file=sys.stderr)
        try:
            with sync_playwright() as p:
                browser = p.chromium.launch(
                    headless=True,
                    args=["--no-sandbox", "--disable-dev-shm-usage", "--disable-gpu"],
                )
                page = browser.new_page()
                page.goto(url, timeout=self.timeout * 1000)
                page.wait_for_selector("div.table-row.ant-row", timeout=8000)
                html = page.content()
                browser.close()

            parsed = self.parse_runner(html)
            parsed["runner_id"] = runner_id
            print(f"[sync] {race_id}/{runner_id} ì™„ë£Œ", file=sys.stderr)
            return parsed

        except PlaywrightTimeoutError:
            print(f"[timeout] {race_id}/{runner_id} ì‹œê°„ ì´ˆê³¼", file=sys.stderr)
        except Exception as e:
            print(f"[error] {race_id}/{runner_id} ì‹¤íŒ¨: {e}", file=sys.stderr)
        return {"runner_id": runner_id, "error": "fetch_failed"}

    def parse_runner(self, html: str) -> Dict[str, Any]:
        """HTML íŒŒì‹± â€” card-player ì¹´ë“œì—ì„œ ì´ë¦„/ì„±ë³„/ë²ˆí˜¸ ì¶”ì¶œ (ì´ë²¤íŠ¸ ì¹´ë“œì™€ êµ¬ë¶„)"""
        soup = BeautifulSoup(html, "lxml")

        # 1) ì„¹ì…˜ í…Œì´ë¸”
        rows = soup.select("div.table-row.ant-row")
        sections = []
        for row in rows:
            cols = [div.get_text(strip=True) for div in row.select("div.ant-col.ant-col-6")]
            if not cols:
                continue
            sections.append({
                "section": cols[0] if len(cols) > 0 else "",
                "pass_time": cols[1] if len(cols) > 1 else "",
                "split_time": cols[2] if len(cols) > 2 else "",
                "total_time": cols[3] if len(cols) > 3 else "",
            })

        # 2) í”Œë ˆì´ì–´ ì¹´ë“œ ë²”ìœ„ í•œì • (ì´ë²¤íŠ¸ ì¹´ë“œì™€ êµ¬ë¶„ë˜ëŠ” í•µì‹¬)
        #    <div class="card-player ant-card ..."> ë‚´ë¶€ì˜ ë©”íƒ€ ì˜ì—­ë§Œ ì‚¬ìš©
        player = soup.select_one("div.card-player.ant-card") or soup.select_one("div.card-player")
        name = gender = bib_no = ""
        event_name = ""

        try:
            # ì´ë²¤íŠ¸ëª…ì€ (ìˆë‹¤ë©´) ì²«ë²ˆì§¸ ì¹´ë“œì˜ ë©”íƒ€ íƒ€ì´í‹€ì—ì„œ ê°€ì ¸ì˜¤ë˜, player ë‚´ë¶€ëŠ” ì œì™¸
            event_title = soup.select_one("div.ant-card:not(.card-player) .ant-card-meta-title")
            if event_title:
                event_name = event_title.get_text(strip=True)

            # í”Œë ˆì´ì–´ ì¹´ë“œì—ì„œ ì´ë¦„/ì„±ë³„/ë°°ë²ˆ ì¶”ì¶œ
            if player:
                name_tag = player.select_one(".ant-card-meta-title")
                desc_tag = player.select_one(".ant-card-meta-description")
            else:
                # fallback (ì´ì „ ë°©ì‹)
                name_tag = soup.select_one("div.ant-card-meta-title")
                desc_tag = soup.select_one("div.ant-card-meta-description")

            if name_tag:
                name = name_tag.get_text(strip=True)

            if desc_tag:
                # ì˜ˆ: "ë‚¨ì | #110" ë˜ëŠ” "ì—¬ì | #220"
                parts = [p.strip() for p in desc_tag.get_text(strip=True).split("|")]
                if parts:
                    # ì²« ìš”ì†Œê°€ ì„±ë³„ì¼ ê°€ëŠ¥ì„± ë†’ìŒ
                    if any(k in parts[0] for k in ("ë‚¨", "ì—¬", "ë‚¨ì", "ì—¬ì", "M", "F")):
                        gender = parts[0]
                    # ë‘ ë²ˆì§¸ ìš”ì†Œê°€ ë°°ë²ˆ
                    if len(parts) >= 2:
                        bib_no = parts[1].replace("#", "").strip()

            # ìµœí›„ ë³´ì •: ì´ë¦„ì´ ë¹„ì—ˆê³  descì— ì´ë¦„ì´ ì„ì—¬ ìˆëŠ” êµ¬ì¡°ì¼ ë•Œ
            if not name and desc_tag:
                # "ê¹€íƒœì¸ | ë‚¨ì | #110" ê°™ì€ ë³€í˜• ëŒ€ì‘
                chunks = [c.strip() for c in desc_tag.get_text(strip=True).split("|")]
                if chunks:
                    name = chunks[0]

        except Exception as e:
            print(f"[íŒŒì‹±ì˜¤ë¥˜] {e}", file=sys.stderr)

        return {
            "name": name or "ì´ë¦„ì—†ìŒ",
            "gender": gender,
            "bib_no": bib_no,
            "event_name": event_name,
            "sections": sections,
        }


    def get_many(self, race_id: int, runner_ids: list[int], limit=4) -> List[Dict[str, Any]]:
        """ThreadPoolExecutor ê¸°ë°˜ ë³‘ë ¬ í¬ë¡¤ë§"""
        print(f"[ğŸš€] ë³‘ë ¬ í¬ë¡¤ë§ ì‹œì‘ (ìµœëŒ€ ë™ì‹œ {limit}ëª…)", file=sys.stderr)
        results = []
        with ThreadPoolExecutor(max_workers=limit) as executor:
            future_map = {executor.submit(self.fetch_html_sync, race_id, rid): rid for rid in runner_ids}
            for fut in as_completed(future_map):
                result = fut.result()
                if result:
                    results.append(result)
        print("[ğŸ§¹] ë¸Œë¼ìš°ì € ì •ìƒ ì¢…ë£Œ", file=sys.stderr)
        return results
